{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c90774f-9862-40e9-8532-efeb3b6b06ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import nbformat\n",
    "import ast\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15cf647-d754-4837-8d60-296aff625da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_functions_and_variables(filename):\n",
    "    with open(filename) as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    function_counter = 0\n",
    "    \n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == \"code\":\n",
    "            try:\n",
    "                code_ast = ast.parse(cell.source)\n",
    "            except SyntaxError:\n",
    "                print(\"SyntaxError when parsing cell. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            functions = [node for node in code_ast.body if isinstance(node, ast.FunctionDef)]\n",
    "            function_counter += len(functions)\n",
    "            \n",
    "            for function in functions:\n",
    "                params = [arg.arg for arg in function.args.args]\n",
    "                print(f\"- Function: {function.name}, Parameters: {params}\")\n",
    "                \n",
    "    print(\"\\nTotal number of functions:\", function_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230dfc62-3b29-4bfe-835b-ab7d5fd540c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_tifs(in_dir):\n",
    "    img_list = []\n",
    "    for file_name in os.listdir(in_dir):\n",
    "        if file_name.endswith('.tif'):\n",
    "            img_list.append(os.path.join(in_dir, file_name))\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03cf394d-fb7a-45a9-a1da-5fb632955d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_median_intensity_histogram(directory, threshold, binsize, title):\n",
    "    median_intensities = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # Remove intensity values less than the threshold\n",
    "            img = img[img >= threshold]\n",
    "            \n",
    "            median_intensity = np.median(img)\n",
    "            median_intensities.append(median_intensity)\n",
    "\n",
    "    plt.hist(median_intensities, bins=binsize)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Median Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dc303ce-4edf-4a8e-a9a2-83fe1cd1f73c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Segments cells based on threshold - 25 is good, images are normalized and scaled\n",
    "def segment_binary_cells(image_input, channel, threshold):\n",
    "    \n",
    "    #select channel of image\n",
    "    image = image_input[channel, :, :]\n",
    "    \n",
    "    # Normalize and scale to 0-255 range\n",
    "    img_array = (image / image.max()) * 255\n",
    "\n",
    "    # Convert to uint8\n",
    "    img_array = img_array.astype(np.uint8)\n",
    "    \n",
    "    #segment image\n",
    "    _, segmented_img = cv2.threshold(img_array, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return img_array, segmented_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee099a-652f-44e1-aba4-dd96c171ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_dilate_binary_cells(image_input, channel, threshold, kernel_size, num_dilation):\n",
    "    \n",
    "    #select channel of image\n",
    "    image = image_input[channel, :, :]\n",
    "    \n",
    "    # Normalize and scale to 0-255 range\n",
    "    img_array = (image / image.max()) * 255\n",
    "\n",
    "    # Convert to uint8\n",
    "    img_array = img_array.astype(np.uint8)\n",
    "    \n",
    "    #segment image\n",
    "    _, segmented_img = cv2.threshold(img_array, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Define a kernel for morphological operations\n",
    "    kernel = np.ones((kernel_size,kernel_size),np.uint8)\n",
    "\n",
    "    # Closing operation to fill small holes\n",
    "    closing = cv2.morphologyEx(segmented_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Dilation operation to merge nearby contours\n",
    "    dilated = cv2.dilate(closing, kernel, iterations = num_dilation)\n",
    "\n",
    "    return img_array, dilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e088f133-be96-4244-80dd-a9b7e22f3699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_segmentation_binary(image_input, channel, threshold):\n",
    "    img_array, segmented_img = segment_binary_cells(image_input, channel, threshold)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(img_array, cmap='gray')\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    ax[1].imshow(segmented_img, cmap='gray')\n",
    "    ax[1].set_title('Binary Segmented Image')\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return img_array, segmented_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a39dcb12-8460-4809-b557-adb640a6cbee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find contours in the binary image and filter for size and touching image border\n",
    "def find_contours(thresh_img, contour_size_limit):\n",
    "    filtered_contours = []\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "       \n",
    "        # Exclude contours touching the edge of the image\n",
    "        if not any(point[0][0] == 0 or point[0][1] == 0 or point[0][0] == thresh_img.shape[1]-1 or point[0][1] == thresh_img.shape[0]-1 for point in contour):\n",
    "            size = cv2.contourArea(contour)\n",
    "           \n",
    "            # Exclude contours less than contour_size_limit\n",
    "            if size > contour_size_limit:\n",
    "                filtered_contours.append(contour)\n",
    "                \n",
    "    return filtered_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "debf8685-d5bb-48d7-b87c-433079a86970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate the maximum convexity defect depth for a contour\n",
    "def max_convexity_defect_depth(contour): \n",
    "    \n",
    "    #some contours trigger errors in calculating defects\n",
    "    try:\n",
    "        hull = cv2.convexHull(contour, returnPoints=False)\n",
    "        defects = cv2.convexityDefects(contour, hull)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle the error here\n",
    "        print(\"Convexity error occured, contour is skipped\")\n",
    "        return float('inf')\n",
    "    \n",
    "    if defects is not None:\n",
    "        depths = [defect[0][3] for defect in defects]\n",
    "        max_depth = max(depths)\n",
    "    else:\n",
    "        max_depth = 0\n",
    "\n",
    "    return max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a4a2c8b-955c-4277-8ce1-054bf6c244a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate the aspect ratio of the fitted ellipse for a contour\n",
    "def aspect_ratio(contour):\n",
    "    # Fit an ellipse to the contour\n",
    "    ellipse = cv2.fitEllipse(contour)\n",
    "  \n",
    "    # Extract the major and minor axes of the ellipse\n",
    "    major_axis, minor_axis = sorted(ellipse[1])\n",
    "\n",
    "    # Calculate the aspect ratio (major_axis / minor_axis)\n",
    "    return major_axis / minor_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77d37906-5c11-4aa6-af39-d220ffa84ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate the area and perimeter of the contour\n",
    "def circularity(contour):\n",
    "    area = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    \n",
    "    # Calculate circularity (4π × area / perimeter²)\n",
    "    if area !=0 and perimeter !=0:\n",
    "        circularity = 4 * np.pi * area / (perimeter * perimeter)\n",
    "    \n",
    "    return circularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c6bf990-1a3e-481e-bd56-1551668d74de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to extract individual cells as images\n",
    "def extract_cell_image(image, contour):\n",
    "    \n",
    "    # Find the bounding box around the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Extract the region of interest (ROI) from the input image\n",
    "    roi = image[y-2:y+h+2, x-2:x+w+2]\n",
    "\n",
    "    return roi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f2bfbb8-5e58-40da-9bcf-73497d2bb768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterates over all images to produce single images\n",
    "# To prevent non specific cell images, only DAPI is used for drawing contours\n",
    "def extract_cells(image_paths, segment_threshold, max_depth_threshold, min_size, out_dir_dapi, out_dir_ab):\n",
    "\n",
    "    #for counting errors and such\n",
    "    total_sc_count = 0\n",
    "    total_mc_count = 0\n",
    "    \n",
    "    #make dirs for sc images\n",
    "    os.makedirs(out_dir_dapi, exist_ok=True)\n",
    "    os.makedirs(out_dir_ab, exist_ok=True)    \n",
    "    \n",
    "    #iterate over each image\n",
    "    img_count = 0\n",
    "    for img_path in image_paths: \n",
    "        img = imread(img_path)\n",
    "        \n",
    "        img_array_DAPI, segmented_DAPI = segment_binary_cells(img, 0, segment_threshold)\n",
    "        img_array_ab, segmented_ab = segment_binary_cells(img, 1, segment_threshold) \n",
    "        \n",
    "        contours_DAPI = find_contours(segmented_DAPI, min_size)\n",
    "        \n",
    "        #filtering based on convexity defect magnitude and writing to dir \n",
    "        sc_count = 0\n",
    "        mc_count = 0\n",
    "        for contour in contours_DAPI:\n",
    "            max_depth = max_convexity_defect_depth(contour)\n",
    "           \n",
    "            if max_depth < max_depth_threshold:\n",
    "                filename = f'{img_count}.{sc_count+1}.png'\n",
    "                \n",
    "                #write\n",
    "                single_cell_dapi = extract_cell_image(img_array_DAPI, contour)\n",
    "                output_path_dapi = os.path.join(out_dir_dapi, filename)\n",
    "                single_cell_ab = extract_cell_image(img_array_ab, contour)\n",
    "                output_path_ab = os.path.join(out_dir_ab, filename)\n",
    "                \n",
    "                \n",
    "                #some images are null, not clear why\n",
    "                try:\n",
    "                    cv2.imwrite(output_path_dapi, single_cell_dapi)\n",
    "                    cv2.imwrite(output_path_ab, single_cell_ab)\n",
    "                    sc_count+=1\n",
    "                \n",
    "                except Exception as e:\n",
    "                    # Handle the error here\n",
    "                    print(\"Unable to write cell image from\", img_path)\n",
    "            else:\n",
    "                mc_count+=1\n",
    "              \n",
    "        total_sc_count+=sc_count\n",
    "        total_mc_count+=mc_count\n",
    "        img_count+=1\n",
    "    print('Finished writing ', total_sc_count, ' single cell images from ', img_count, ' images')\n",
    "    print('Removed ',  total_mc_count, ' multi cell images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a219bdeb-50d3-47c7-8da6-2412a3d2a83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_maskedbg_cell(image_paths, segment_threshold, max_depth_threshold, min_contour_size, out_dir_dapi, out_dir_ab):\n",
    "    \n",
    "    total_sc_count = 0\n",
    "    total_mc_count = 0\n",
    "\n",
    "    os.makedirs(out_dir_dapi, exist_ok=True)\n",
    "    os.makedirs(out_dir_ab, exist_ok=True)\n",
    "\n",
    "    img_count = 0\n",
    "    for img_path in image_paths:\n",
    "        img = imread(img_path)\n",
    "\n",
    "        img_array_DAPI, segmented_DAPI = segment_binary_cells(img, 0, segment_threshold)\n",
    "        img_array_ab, segmented_ab = segment_binary_cells(img, 1, segment_threshold)\n",
    "\n",
    "        contours_DAPI = find_contours(segmented_DAPI, min_contour_size)\n",
    "\n",
    "        sc_count = 0\n",
    "        mc_count = 0\n",
    "        for contour in contours_DAPI:\n",
    "            max_depth = max_convexity_defect_depth(contour)\n",
    "\n",
    "            if max_depth < max_depth_threshold:\n",
    "                filename = f'{img_count}.{sc_count+1}.png'\n",
    "                \n",
    "                # Create a mask with the same shape as the contour\n",
    "                mask = np.zeros_like(img_array_DAPI)\n",
    "                cv2.drawContours(mask, [contour], 0, (255), thickness=-1)\n",
    "\n",
    "                # Apply the mask to the cell images\n",
    "                whole_img_mask_dapi = cv2.bitwise_and(img_array_DAPI, mask)\n",
    "                whole_img_mask_ab = cv2.bitwise_and(img_array_ab, mask)\n",
    "\n",
    "                masked_single_cell_dapi = extract_cell_image(whole_img_mask_dapi, contour)\n",
    "                masked_single_cell_ab = extract_cell_image(whole_img_mask_ab, contour)\n",
    "                \n",
    "                # Write masked cell images\n",
    "                output_path_dapi = os.path.join(out_dir_dapi, filename)\n",
    "                output_path_ab = os.path.join(out_dir_ab, filename)\n",
    "\n",
    "                try:\n",
    "                    cv2.imwrite(output_path_dapi, masked_single_cell_dapi)\n",
    "                    cv2.imwrite(output_path_ab, masked_single_cell_ab)\n",
    "                    sc_count+=1\n",
    "                except Exception as e:\n",
    "                    print(\"Unable to write cell image from\", img_path)\n",
    "            else:\n",
    "                mc_count+=1\n",
    "\n",
    "        total_sc_count+=sc_count\n",
    "        total_mc_count+=mc_count\n",
    "        img_count+=1\n",
    "    print('Finished writing ', total_sc_count, ' single cell images with BG mask from ', img_count, ' images')\n",
    "    print('Removed ',  total_mc_count, ' multi cell images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa0e4192-4501-4453-8715-86fc54d67a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_maskedbg_cell_merge(image_paths, segment_threshold, max_depth_threshold, out_dir_combined):\n",
    "    \n",
    "    total_sc_count = 0\n",
    "    total_mc_count = 0\n",
    "\n",
    "    os.makedirs(out_dir_combined, exist_ok=True)\n",
    "\n",
    "    img_count = 0\n",
    "    for img_path in image_paths:\n",
    "        img = imread(img_path)\n",
    "\n",
    "        img_array_DAPI, segmented_DAPI = segment_binary_cells(img, 0, segment_threshold)\n",
    "        img_array_ab, segmented_ab = segment_binary_cells(img, 1, segment_threshold)\n",
    "\n",
    "        contours_DAPI = find_contours(segmented_DAPI, 500)\n",
    "\n",
    "        sc_count = 0\n",
    "        mc_count = 0\n",
    "        for contour in contours_DAPI:\n",
    "            max_depth = max_convexity_defect_depth(contour)\n",
    "            if max_depth < max_depth_threshold:\n",
    "                filename = f'{img_count}.{sc_count+1}'\n",
    "                \n",
    "                # Create a mask with the same shape as the contour\n",
    "                mask = np.zeros_like(img_array_DAPI)\n",
    "                cv2.drawContours(mask, [contour], 0, (255), thickness=-1)\n",
    "\n",
    "                # Apply the mask to the cell images\n",
    "                whole_img_mask_dapi = cv2.bitwise_and(img_array_DAPI, mask)\n",
    "                whole_img_mask_ab = cv2.bitwise_and(img_array_ab, mask)\n",
    "\n",
    "                masked_single_cell_dapi = extract_cell_image(whole_img_mask_dapi, contour)\n",
    "                masked_single_cell_ab = extract_cell_image(whole_img_mask_ab, contour)\n",
    "                \n",
    "                 # Stack the channels\n",
    "                combined_image = np.stack((masked_single_cell_dapi, masked_single_cell_ab), axis=-1)\n",
    "\n",
    "                # Write masked cell images\n",
    "                output_path_combined = os.path.join(out_dir_combined, filename)\n",
    "\n",
    "                try:\n",
    "                    np.save(output_path_combined, combined_image)\n",
    "                    sc_count+=1\n",
    "                except Exception as e:\n",
    "                    print(\"Unable to write cell image from\", img_path)\n",
    "            else:\n",
    "                mc_count+=1\n",
    "\n",
    "        total_sc_count+=sc_count\n",
    "        total_mc_count+=mc_count\n",
    "        img_count+=1\n",
    "        \n",
    "    print('Finished writing ', total_sc_count, ' single cell images with BG mask from ', img_count, ' images')\n",
    "    print('Removed ',  total_mc_count, ' multi cell images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "935ff64f-035e-498f-8310-2ebffa4fbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows n number of images in the specified directory and prints total number of images \n",
    "\n",
    "def show_n_random_images(img_dir, n, row_length):\n",
    "    \n",
    "    # get list of png files in directory\n",
    "    png_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    # choose n random png files\n",
    "    random_png_files = random.sample(png_files, n)\n",
    "\n",
    "    # display images\n",
    "    print('Displaying ', n, ' images out of ', len(png_files), ' in ', img_dir)\n",
    "    fig, axs = plt.subplots((n+row_length-1)//row_length, row_length, figsize=(row_length*2.5,15))\n",
    "    axs = axs.ravel()\n",
    "    \n",
    "    for i, file in enumerate(random_png_files):\n",
    "        img_path = os.path.join(img_dir, file)\n",
    "        img = Image.open(img_path)\n",
    "        axs[i].imshow(np.array(img), cmap='gray')\n",
    "        axs[i].set_title(file)\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    return random_png_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc015083-ae59-43df-8527-7b9c59b6b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(img_dir, filepaths):\n",
    "    \n",
    "    n = len(filepaths)\n",
    "\n",
    "    # display images\n",
    "    print('Displaying ', n, ' images in ', img_dir)\n",
    "    fig, axs = plt.subplots((n+4)//5, 5, figsize=(15,15))\n",
    "    axs = axs.ravel()\n",
    "    \n",
    "    for i, file in enumerate(filepaths):\n",
    "        img_path = os.path.join(img_dir, file)\n",
    "        img = Image.open(img_path)\n",
    "        axs[i].imshow(np.array(img), cmap='gray')\n",
    "        axs[i].set_title(file)\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5707ed20-d0d6-4ca8-83b8-af744db23062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_batch(train_loader):\n",
    "    data_iter = iter(train_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    num_images = images.size(0)\n",
    "    \n",
    "    nrows = (num_images + 7) // 8\n",
    "    ncols = min(num_images, 8)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(2 * ncols, 2 * nrows))\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            idx = i * 8 + j\n",
    "            if idx < num_images:\n",
    "                img = images[idx].numpy().transpose((1, 2, 0))\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "                if nrows == 1:\n",
    "                    axes[j].imshow(img)\n",
    "                    axes[j].axis('off')\n",
    "                else:\n",
    "                    axes[i, j].imshow(img)\n",
    "                    axes[i, j].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5653d2f1-5edc-44ce-8d22-cb217d8a0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_data(train_dir, test_dir, data_dir, file_num_limit):\n",
    "    \n",
    "    base_data_dir = os.path.basename(data_dir)\n",
    "    image_files = [f for f in os.listdir(data_dir) if f.endswith('.png')]\n",
    "\n",
    "    # Split the images into training and test sets\n",
    "    train_files, test_files = train_test_split(image_files, test_size=0.1, random_state=42)\n",
    "    train_files_subset = random.sample(train_files, file_num_limit)\n",
    "    \n",
    "    # Create the training and test directories\n",
    "    train_dir = os.path.join(train_dir, base_data_dir)\n",
    "    test_dir = os.path.join(test_dir, base_data_dir)\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Copy the training images to the training directory\n",
    "    for f in train_files_subset:\n",
    "        src = os.path.join(data_dir, f)\n",
    "        dst = os.path.join(train_dir, os.path.basename(f))\n",
    "        copyfile(src, dst)\n",
    "\n",
    "    # Copy the test images to the test directory\n",
    "    for f in test_files:\n",
    "        src = os.path.join(data_dir, f)\n",
    "        dst = os.path.join(test_dir, os.path.basename(f))\n",
    "        copyfile(src, dst)\n",
    "    \n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87e90d08-88b9-403b-b2e7-16652e5d3a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_load_data(train_dir, test_dir, batchsize, transform_x, transform_y, mean, std):\n",
    "    # Define transforms for training and testing data\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((transform_x, transform_y)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((transform_x, transform_y)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "    # Load the datasets\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batchsize, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batchsize, shuffle=True)\n",
    "    total_step = len(train_loader)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15a4ba1e-1b88-4e25-a2a8-54c6983bc06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_load_data_nonorm(train_dir, test_dir, batchsize, transform_x, transform_y):\n",
    "    # Define transforms for training and testing data\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((transform_x, transform_y)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((transform_x, transform_y)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Load the datasets\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batchsize, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batchsize, shuffle=True)\n",
    "    total_step = len(train_loader)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4944f70-c92f-4672-907e-32d697443d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_std(train_dir):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset=train_data, batch_size=64)\n",
    "    mean, std = 0, 0\n",
    "    for images, _ in dataloader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "    mean /= len(dataloader.dataset)\n",
    "    std /= len(dataloader.dataset)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "697d1340-560b-46f3-9905-b4e2b9c1f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the specified model for a set number of epochs\n",
    "def train_model(model, train_loader, test_loader, optimizer, criterion, num_epochs, csv_name, save_model_name=None):\n",
    "    \n",
    "    #vars for saving model only\n",
    "    valid_test = float('inf')\n",
    "    best_valid_epoch = 0\n",
    "    \n",
    "    #for counting time for training\n",
    "    t1 = time.perf_counter()\n",
    "    print('Begin model training for {} epochs'.format(num_epochs))\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    time_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "\n",
    "        #Training \n",
    "        correct_t = 0\n",
    "        total_t = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs) #tensor produced, indecipherable when printed \n",
    "            loss = criterion(outputs, labels) #criterion is loss function\n",
    "            loss.backward() #used to calculate the gradients of the parameters of a model with respect to a loss function\n",
    "            optimizer.step() #updates the model parameters based on the gradients computed during the backward pass of training\n",
    "\n",
    "            _, preds = torch.max(outputs, 1) #produces tensor containing indices of the maximum values (i.e. the predicted classes)\n",
    "            correct_t += (preds == labels).sum().item()\n",
    "            train_loss += loss.item()\n",
    "            total_t += labels.size(0) #total equals 50000 by the end of this for loop for CIFAR10\n",
    "            #correct_t += (preds == labels).sum().item()\n",
    "            #print(preds==labels)\n",
    "            #print()\n",
    "\n",
    "        #Validation\n",
    "        correct_v = 0\n",
    "        total_v = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader, 0):\n",
    "                inputs, labels = data\n",
    "                #optimizer.zero_grad() #can probably be removed - no parameters being updated\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_v += (preds == labels).sum().item()\n",
    "                test_loss += loss.item()\n",
    "                total_v += labels.size(0) #total equals 10000 by the end of this for loop for CIFAR10\n",
    "\n",
    "        #defining accuracy and loss \n",
    "        t_acc = correct_t/total_t\n",
    "        v_acc = correct_v/total_v\n",
    "        new_train_loss = train_loss / len(train_loader)\n",
    "        new_valid_loss = test_loss / len(test_loader)\n",
    "\n",
    "        #prints stuff\n",
    "        t2 = time.perf_counter()\n",
    "        print('Training loss for Epoch {} is {:.4f} and Training accuracy is {:.3f}'.format(epoch + 1, new_train_loss, t_acc))\n",
    "        print('Validation loss for Epoch {} is {:.4f} and Validation accuracy is {:.3f}'.format(epoch + 1, new_valid_loss, v_acc))\n",
    "        print('Completed Epoch {} in {:.1f} seconds'.format(epoch + 1, t2-t1))\n",
    "\n",
    "        #makes list of loss, accuract, and time for epoch\n",
    "        train_acc.append(t_acc)\n",
    "        test_acc.append(v_acc)\n",
    "        train_losses.append(new_train_loss)\n",
    "        test_losses.append(new_valid_loss)\n",
    "        time_list.append(t2-t1)\n",
    "\n",
    "        #saves the model if validation loss has decreased\n",
    "        if new_valid_loss < valid_test and save_model_name is not None:\n",
    "            #saving model...\n",
    "            if save_model_name.endswith(\".pt\") and isinstance(save_model_name, str):\n",
    "                torch.save(model.state_dict(), save_model_name)\n",
    "                print ('Test loss improvement ({:.4f} -----> {:.4f}), model saved as {}'.format(valid_test, new_valid_loss, save_model_name))\n",
    "                valid_test = new_valid_loss\n",
    "                best_valid_epoch = epoch + 1\n",
    "            \n",
    "            else:\n",
    "                print(\"Model name is in wrong form (ends with .pt)\")\n",
    "            \n",
    "        else:\n",
    "            print('No improvement in test loss, best model saved at Epoch {} with validation loss of {:.4f}').format(best_valid_epoch, valid_test)        \n",
    "\n",
    "        # Write train and test lists to a CSV file\n",
    "        with open(csv_name, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Training Loss', 'Test Loss', 'Train Accuracy', 'Test Accuracy', 'Time'])\n",
    "            rows = zip(train_losses, test_losses, train_acc, test_acc, time_list)\n",
    "            writer.writerows(rows)    \n",
    "        \n",
    "    return train_losses, test_losses, train_acc, test_acc, time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e4d4b6f-2972-4366-bc53-f4d531c5722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thx chatgpt\n",
    "def show_images_from_loader(loader, labels=None, num_batches=1, batch_size=20):\n",
    "    # Get specified number of batches from the loader\n",
    "    images = []\n",
    "    actual_labels = []\n",
    "    for i, (image_batch, label_batch) in enumerate(loader):\n",
    "        if i == num_batches:\n",
    "            break\n",
    "        images.append(image_batch)\n",
    "        actual_labels.append(label_batch)\n",
    "\n",
    "    images = torch.cat(images, dim=0)\n",
    "    actual_labels = torch.cat(actual_labels, dim=0)\n",
    "    \n",
    "    # If labels are specified, filter the images and labels based on the specified labels\n",
    "    if labels is not None:\n",
    "        mask = torch.zeros_like(actual_labels, dtype=torch.bool)\n",
    "        for label in labels:\n",
    "            mask = mask | (actual_labels == label)\n",
    "        images = images[mask]\n",
    "        actual_labels = actual_labels[mask]\n",
    "    \n",
    "    # Plot the images\n",
    "    num_images = min(batch_size*num_batches, len(images))\n",
    "    num_rows = (num_images + batch_size - 1) // batch_size\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=batch_size, figsize=(12, 6*num_rows),\n",
    "                             subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_images:\n",
    "            ax.imshow(np.transpose(images[i], (1, 2, 0)))\n",
    "            ax.set_title(f'Label: {actual_labels[i].item()}')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dee9d2b7-8e40-483c-8103-200d433e327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model, device, test_loader, classes):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true += labels.tolist()\n",
    "            y_pred += preds.tolist()\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "    print('Test loss: %d %%' % (None))\n",
    "\n",
    "    \n",
    "    # Generate a confusion matrix\n",
    "    labels = list(range(len(classes)))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    print(cm)\n",
    "\n",
    "    # Output the sum of each row as a list and print it\n",
    "    sum_by_row = cm.sum(axis=1).tolist()\n",
    "    print(\"Sum by row:\", sum_by_row)\n",
    "    \n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "    # Normalize color intensity to the row\n",
    "    plt.imshow(np.log(cm_norm), interpolation='nearest', cmap='Blues')\n",
    "\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' #2 decimal places\n",
    "    thresh = cm_norm.max() / 3.\n",
    "    for i in range(cm_norm.shape[0]):\n",
    "        for j in range(cm_norm.shape[1]):\n",
    "            plt.text(j, i, format(cm_norm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm_norm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a57ecee-7b45-4825-9323-829b602c5ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, device, test_loader, num_classes):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true += labels.tolist()\n",
    "            y_pred += preds.tolist()\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "    # Generate a confusion matrix\n",
    "    labels = list(range(num_classes))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    print(cm)\n",
    "\n",
    "    # Output the sum of each row as a list and print it\n",
    "    row_labels = ['True Label ' + str(i) for i in range(num_classes)]\n",
    "    sum_by_row = cm.sum(axis=1).tolist()\n",
    "    row_dict = OrderedDict(zip(row_labels, sum_by_row))\n",
    "    print(\"Sum by row:\", row_dict)\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46942b06-701a-4d6c-98cf-89ee6aa014d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged two functions\n",
    "#Validation\n",
    "def eval_and_plot(model, criterion, device, test_loader, num_classes, class_labels):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true += labels.tolist()\n",
    "            y_pred += preds.tolist()\n",
    "            test_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "    print('Test loss of the network on the test images is:', test_loss)\n",
    "          \n",
    "    # Generate a confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=class_labels)\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    print(cm)\n",
    "\n",
    "    # Output the sum of each row as a list and print it\n",
    "    row_labels = ['True Label ' + str(i) for i in class_labels]\n",
    "    sum_by_row = cm.sum(axis=1).tolist()\n",
    "    row_dict = OrderedDict(zip(row_labels, sum_by_row))\n",
    "    print(\"Sum by row:\", row_dict)\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "    # Normalize color intensity to the row\n",
    "    plt.imshow(np.log(cm_norm), interpolation='nearest', cmap='Blues')\n",
    "\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(class_labels))\n",
    "    plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, class_labels)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm_norm.max() / 3.\n",
    "    for i in range(cm_norm.shape[0]):\n",
    "        for j in range(cm_norm.shape[1]):\n",
    "            plt.text(j, i, format(cm_norm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm_norm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d108f-d738-4791-8a6c-03471ec986f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024f373-50c3-4df5-b1f8-f24c08a2d2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a1c34-7324-40f6-b5f8-da69da35df7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
